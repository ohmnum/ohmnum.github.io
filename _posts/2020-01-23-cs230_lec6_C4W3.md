---
title: "cs230_lec6_C4W3"
categories: 
  - cs230 온라인 
toc: true
---
## Object localization
- Image classification은 이미지가 어떠한 종류인지 구분 
- Classification with localization : 종류인지 구분+ 위치 
- Detection : 감지하는 물체가 1개 이상임
### Classification with localization
- 대부분 softmax층으로 (물체1, 물체2, 배경) 등으로 물체를 확인함
- Localization은 추가로 층을 만들어서 결과를 출력하게 한다. 
  - bx,by,bw,bh에 관한 정보(b : bounding box)
- 출력 y 정의
  - y의 첫번째 구성요소인 $p_c$는 물체가 있는지 확인(0, 1)
  - y의 다음 구성요소는 bx,by,bh,bw
  - y의 그 다음으로는 c1, c2, c3 ~ (각 클래스 분류)
- $p_c=0$이면 뒤에는 고려할 필요가 없음
- loss function은 
  - if $$y_1=1$$ : 각각의 차이 손실값의 제곱을 더한 것과 같다
  - if $$y_1=0$$ : $y_1$의 차이 손실의 제곱을 더한 것과 같다 

## Landmark Detection
- 이미지에서 중요한 점을 찾는 것
- 왼쪽 눈고리를 찾는 문제면 $l_{1x},l_{1y}$
- 여러 점을 찾는 문제면 $l_{1x},l_{1y},l_{2x},l_{2y}, \cdots$
- 해당 정보를 포함하는 신경망을 만들면 이를 찾을 수 있음

## Object detection
- 레이블된 데이터가 있어야 함 (자동차 부분만 잘라내기)
- **슬라이딩 윈도우 방식**
  - 그림의 처음부터 끝까지 박스 위치를 약간씩 바꿔가면서 해당 위치에 원하는 object가 있는지 확인하는 것
  - 윈도우 박스의 크기를 갈수록 크게 하면서 검증
  - 단점으로는 각 윈도우에 대해서 합성곱 계산을 해야 하기 때문에 단일 객체 인식 시 계산 비용이 엄청 크게 발생한다 
  - 신경망 전에는 선형 분류기 같은것을 사용해서 슬라이딩 윈도우 방식을 써도 그렇게 계산비용이 많이 들지 않았다.

## Convolution implementation of sliding windows(논문명)
![](/assets/img/images/2020-01-23-17-23-56.png)
- FC 레이어 대신 이미지의 크기에 맞는 합성곱 신경망 사용

![](/assets/img/images/2020-01-23-17-15-20.png)
- 합성곱을 통해 각 슬라이딩 윈도우를 동시에 처리할 수 있다.
- 맨위의 작업을 픽셀이 확장되어도 다음과 같이 계산 가능
- 보다 효율적인 계산 가능
![](/assets/img/images/2020-01-23-17-34-10.png)
- 큰 합성곱을 사용해서 한번에 사용 가능

![](/assets/img/images/2020-01-23-17-37-01.png)
- 문제점 : 경계 상자의 위치가 정확하지 않을 수 있다
- 실제로 경계 상자도 네모나지 않을 수 있다

## YOLO Algorithm (논문- 읽기 어려움)
![](/assets/img/images/2020-01-23-17-46-42.png)
- 위의 문제점을 해결하기 위한 알고리즘
- 그리드를 그려서 이미지를 나누고 각각의 그리드에 대해서 Classification with localization 알고리즘 실행
- 합성곱을 통해서 적용가능하다. 그리드가 9개라고 해서 9번 실행하는 것이 아니라 한번의 신경망에서 진행된다.
- 위에는 3X3 예시를 들었지만 더 fine하게 19X19하게 해도 된다.
- bx,by,bw,bh정의
  - bx,by는 0에서 1사이에 있음
  - bw,bh는 1을 넘을 수 있음(이미지가 박스보다 클수 있으므로)
  - 다른 parameterization 방식이 있지만 해당 방식도 잘 작동한다

## Intersection over union(IOU)
- 물체 감지 알고리즘의 작동 성능 평가
- 감지 박스와 실제 경계 박스의 교집합의 크기를 계산하는 것
  $$IOU=\frac{size \ of \ intersection}{size \ of \ detection \ box}$$
- IOU 값이 높을 수록 잘 작동한다고 본다(보통 0.5이상)

## Non-max suppression(비-최대값 억제)
- 알고리즘이 각 물체를 한번씩만 인식하도록 하는 것
- 정리하자면 감지된 값들을 정리하는 것
![](/assets/img/images/2020-01-23-17-58-46.png)
  - 1) 가장 Pc가 높게 나온 상자를 표시
  - 2) 해당 박스와 IOU가 높은 다른 박스 삭제
  - 3) 그다음에 가장 높은 Pc가 나온 상자 표시
  - 4) 해당 박스와 IOU가 높은 다른 박스 삭제 
  - 5) 반복 (클래스가 많으면 전체 과정을 클래스의 수만큼 거쳐야 함)

## Anchor box(앵커 박스)
- 격자 셀이 여러 물체를 관찰하고 싶을 때 사용
![](/assets/img/images/2020-01-23-18-06-23.png)
- 앵커 박스의 개수를 정의함
- 비용 레이블을 감지할 물체의 개수만큼 추가하여 정의
  ![](/assets/img/images/2020-01-24-11-30-27.png)
  - 기존 방식과 비교하면 다음과 같다
  ![](/assets/img/images/2020-01-24-11-38-58.png)
  - 3가지 박스가 있는 경우는 위 알고리즘이 다룰 수 없음. 그리드가 많을수록 위의 경우는 거의 없어지나 학습 알고리즘이 더 전문화되는 계기를 줌
  - 두 물체가 격자 셀에 연관되고 같은 앵커 박스를 같는 경우도 다룰 수 없음
  - 자동으로 앵커 박스를 고르는 방식도 있음(심화)
